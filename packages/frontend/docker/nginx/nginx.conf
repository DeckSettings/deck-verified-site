user  nginx;
worker_processes  auto;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for" "served_by:$served_by"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    # Map for search engine bots based on the User-Agent header
    # Identify Bot Traffic for Page Replica (https://github.com/Page-Replica/page-replica)
    map $http_user_agent $search_engines {
        "~bingbot"                 1;
        "~BingPreview"             1;
        "~Googlebot"               1;
        "~GoogleOther"             1;
        "~Google-InspectionTool"   1;
        "~Mediapartners-Google"    1;
        "~AdsBot-Google-Mobile"    1;
        "~AdsBot-Google"           1;
        "~Slurp"                   1;
        "~DuckDuckBot"             1;
        "~Baiduspider"             1;
        "~YandexBot"               1;
        "~Sogou"                   1;
        "~Exabot"                  1;
        "~ia_archiver"             1;
        "~propellerads"            1;
        "~ChatGPT"                 1;
        "~openai"                  1;
        "~Uptime-BotTest"          1;
    }

    # Map for social networks based on the User-Agent header (case-insensitive)
    map $http_user_agent $social_networks {
        "~*meta"                   1;
        "~*facebook"               1;
        "~*twitter"                1;
        "~*linkedin"               1;
        "~*reddit"                 1;
        "~*telegram"               1;
        "~*rest-client"            1;
    }

    # Create Map to identify if the referrer is from Google or Facebook
    map $http_referer $ref_from_gf {
        default 0;
        ~*^https?://([a-z0-9-]+\.)*google\.[a-z.]+/   1;
        ~*^https?://([a-z0-9-]+\.)*facebook\.com/     1;
    }

    # Combine the maps into an "needs_ssr" variable.
    # If either map matches (resulting in a non-empty value), needs_ssr will be set to 1.
    # Format: "<search_engines>:<social_networks>:<ref_from_gf>"
    map "$search_engines:$social_networks:$ref_from_gf" $needs_ssr {
        "~^1"                       1;  # search engine bot (first field = 1)
        "~^([^:]*):1:"              1;  # social bot (second field = 1)
        "~:1$"                      1;  # google/facebook referrer (third field = 1)
        default                     0;
    }

    server {
        listen 9021;
        server_name localhost;

        add_header X-Frame-Options "SAMEORIGIN";
        add_header X-XSS-Protection "1; mode=block";
        add_header X-Content-Type-Options "nosniff";

        charset utf-8;

        # Ensure relative redirects stay relative behind a reverse proxy
        absolute_redirect off;

        # Enable gzip compression
        gzip on;
        gzip_disable "msie6";
        gzip_vary on;
        gzip_proxied any;
        gzip_comp_level 6;
        gzip_buffers 16 8k;
        gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

        # Set the root for static files
        root /usr/share/nginx/html;

        # Set a default value: requests will be marked as served by "files"
        set $served_by "local";

        # Serve root (/) with SPA, and proxy bots to SSR
        location / {
            set $served_by "local:spa";

            # Re-route bots to SSR
            error_page 418 = @proxy;
            if ($needs_ssr) {
                return 418;
            }

            # Load SPA files
            index index.html;
            try_files $uri $uri/ /index.html;

            # Prevent browser cache for HTML
            add_header Last-Modified $date_gmt;
            add_header Cache-Control "no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0";
            if_modified_since off;
            expires off;
            etag off;
        }

        location = /deck-verified/health {
            set $served_by "local:healthcheck";
            default_type text/plain;
            return 200 "OK";
            access_log off;
        }

        # Proxy API requests
        location ^~ /deck-verified/api/ {
            set $served_by "proxy:api";
            proxy_pass http://api:9022/deck-verified/api/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Serve JavaScript, CSS, and static assets with browser cache
        location ~* \.(?:js|css|woff2?|ttf|otf|eot|svg|ico|jpg|jpeg|png|gif|webp|mp4|json)$ {
            set $served_by "local:assets";

            # Re-route bots to SSR
            error_page 418 = @proxy;
            if ($needs_ssr) {
                return 418;
            }

            # Load SPA asset files
            try_files $uri $uri/ =404;

            # Force browser cache
            expires max;
            access_log off;
            add_header Cache-Control "public, max-age=31536000, immutable";
        }

        # Legacy redirect: move old /deck-verified/ paths to root
        # TODO: Remove this after 01/12/2025
        location ~ ^/deck-verified/(.*)$ {
            set $served_by "local:legacy-redirect";
            rewrite ^/deck-verified/(.*)$ /$1 permanent;
        }

        # Internal location for proxying bot requests.
        # Note: No URI part is included in proxy_pass because doing it this way the original URI (/deck-verified/**) is still preserved.
        location @proxy {
            set $served_by "proxy:web-ssr";
            proxy_pass http://web-ssr:3000;
        }

        # Serve robots.txt from API
        location = /robots.txt {
            set $served_by "proxy:robots";
            access_log off;
            log_not_found off;
            proxy_pass http://api:9022/robots.txt;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Serve sitemap.xml from API
        location = /sitemap.xml {
            set $served_by "proxy:sitemap";
            access_log off;
            log_not_found off;
            proxy_pass http://api:9022/sitemap.xml;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            # TODO: Test using a cache for this request
            #add_header X-Cache $upstream_cache_status;
        }

        # Serve error pages
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html;
        }

        # Block hidden files (except those under the .well-known/** path)
        location ~ /\.(?!well-known).* {
            deny all;
        }
    }
}
